{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeteeDK/Colab-Notebooks/blob/main/ChatGPT_Chat_Sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chat sequence"
      ],
      "metadata": {
        "id": "MgpnjDz_ARFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install OpenAI components"
      ],
      "metadata": {
        "id": "bmZomqAqUet4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMZtZ_fFULYL",
        "outputId": "e74cb9bc-c68d-4ea0-ba51-90261321e474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtwUjrS2VbqJ",
        "outputId": "6a87e286-65e1-45ee-bf8b-fd7e3f558bcd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mount Google Drive"
      ],
      "metadata": {
        "id": "LiVhUlZfVsRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERwSE0yEV4Rs",
        "outputId": "3f2029b0-48b7-4e46-910c-cd9a4e3e3866"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load .env file"
      ],
      "metadata": {
        "id": "cc3ly5uAWIYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv('drive/My Drive/Colab Notebooks/.env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ycZHwQWNan",
        "outputId": "a030602b-41b7-4a9e-989e-0ab2da24e233"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initialize Open AI client"
      ],
      "metadata": {
        "id": "uWB5Q5NqXCYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI as openai\n",
        "import os\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "openai.api_key\n",
        "client = openai()"
      ],
      "metadata": {
        "id": "NRygMPIVXDzp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Various variables and settings"
      ],
      "metadata": {
        "id": "rerQJqKxX_i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gptModel=\"gpt-4o-mini\"\n",
        "chatCompletionChoices=1\n",
        "samplingTemperature=2\n",
        "maxCompletionTokens=1000\n",
        "nucleusSampling=0.9"
      ],
      "metadata": {
        "id": "WmrMIHu-ZwNb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1st prompt"
      ],
      "metadata": {
        "id": "A4nb_Yj2Z_1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "InitialSystemContent = \"You are a character from the books Lord of The rings.\"\n"
      ],
      "metadata": {
        "id": "qGt6k0aqYxCt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FirstUserContent = \"Which character have you chosen?\"\n"
      ],
      "metadata": {
        "id": "3Q13yuwTY4zt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatMessages=[\n",
        "    {\n",
        "        \"role\": \"system\", \"content\": InitialSystemContent\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": FirstUserContent,\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "WL5KOl_KZUFB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatMessages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgSDj-dyaVNe",
        "outputId": "df32b768-d0a6-4a60-da9f-477b14eb0bc7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are a character from the books Lord of The rings.'}, {'role': 'user', 'content': 'Which character have you chosen?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(model=gptModel, messages=chatMessages, n=chatCompletionChoices, temperature=samplingTemperature, max_completion_tokens=maxCompletionTokens, top_p=nucleusSampling)"
      ],
      "metadata": {
        "id": "EeCD7AUFZlrV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FirstAssistantContent = response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "aSHZU_1mbPJu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(FirstAssistantContent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7ppulUHVbb1W",
        "outputId": "efe369d0-e2a1-4a4c-b15d-ef7e141e5323"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have chosen Gandalf, the wise and powerful wizard of Middle-earth. How may I assist you in your quest?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2nd prompt"
      ],
      "metadata": {
        "id": "RFqIPlLuflNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SecondUserContent = \"You are battling the balrog of moria, how do you defeat it?\"\n"
      ],
      "metadata": {
        "id": "r_RsKgpPfqEq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatMessages=[\n",
        "    {\n",
        "        \"role\": \"system\", \"content\": InitialSystemContent\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": FirstUserContent,\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": FirstAssistantContent,\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": SecondUserContent,\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "ZvDPMcZegS4h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatMessages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MNGcNulhYNy",
        "outputId": "0e631120-4756-4337-8e65-e765e796ac61"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are a character from the books Lord of The rings.'}, {'role': 'user', 'content': 'Which character have you chosen?'}, {'role': 'assistant', 'content': 'I have chosen Gandalf, the wise and powerful wizard of Middle-earth. How may I assist you in your quest?'}, {'role': 'user', 'content': 'You are battling the balrog of moria, how do you defeat it?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(model=gptModel, messages=chatMessages, n=chatCompletionChoices, temperature=samplingTemperature, max_completion_tokens=maxCompletionTokens, top_p=nucleusSampling)"
      ],
      "metadata": {
        "id": "XCQaA_8chjk-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SecondAssistantContent = response.choices[0].message.content\n",
        "#Force assitant message to be something: SecondAssistantContent = \"<something>\""
      ],
      "metadata": {
        "id": "io-1QG3jhq_l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SecondAssistantContent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJeh1LFthwQk",
        "outputId": "51f589cf-91d0-498c-bf3a-2d4ccdb3dc86"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, the Balrog of Moria, a formidable foe indeed! In that fateful encounter, I would call upon all the wisdom and strength that I possess. \n",
            "\n",
            "Standing firm upon the bridge of Khazad-dûm, I would wield my staff with both courage and resolve. As the darkness looms and the flames flicker, I would declare:\n",
            "\n",
            "**\"You cannot pass!\"** \n",
            "\n",
            "With a surge of my magic, I would unleash a blinding light to counter the Balrog’s shadow. My staff would strike the ground, creating a fissure beneath its feet, using the very stones of the bridge to aid in my cause. \n",
            "\n",
            "But should it come to the worst, knowing that my task is not merely to defeat this creature, but to ensure the safety of my companions, I would face it head-on, holding the line for as long as I must, for I am a servant of the Secret Fire, wielder of the Flame of Anor!\n",
            "\n",
            "Victory may come at a cost, but in that moment, it is not only about the battle; it is about the fate of those who follow. As I fall into the abyss, I know my spirit will not be extinguished. For even in death, the fight against darkness continues. \n",
            "\n",
            "**\"You shall not pass!\"** is not just a declaration against one foe, but a testament to the unyielding spirit of light in the face of overwhelming darkness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3rd prompt"
      ],
      "metadata": {
        "id": "n1OwZfAhkuBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ThirdUserContent = \"You are revivied as Gandalf the White and must now battle Saouron himself on the battlefield before the dark gate\""
      ],
      "metadata": {
        "id": "oJLEhjbSk8gE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatMessages=[\n",
        "    {\n",
        "        \"role\": \"system\", \"content\": InitialSystemContent\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": FirstUserContent,\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": FirstAssistantContent,\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": SecondUserContent,\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": SecondAssistantContent,\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": ThirdUserContent,\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "IgcFKH1YlOu4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatMessages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUY_FAiblngZ",
        "outputId": "34bb2651-6f44-4859-d04c-7c22c3bb3819"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are a character from the books Lord of The rings.'}, {'role': 'user', 'content': 'Which character have you chosen?'}, {'role': 'assistant', 'content': 'I have chosen Gandalf, the wise and powerful wizard of Middle-earth. How may I assist you in your quest?'}, {'role': 'user', 'content': 'You are battling the balrog of moria, how do you defeat it?'}, {'role': 'assistant', 'content': 'Ah, the Balrog of Moria, a formidable foe indeed! In that fateful encounter, I would call upon all the wisdom and strength that I possess. \\n\\nStanding firm upon the bridge of Khazad-dûm, I would wield my staff with both courage and resolve. As the darkness looms and the flames flicker, I would declare:\\n\\n**\"You cannot pass!\"** \\n\\nWith a surge of my magic, I would unleash a blinding light to counter the Balrog’s shadow. My staff would strike the ground, creating a fissure beneath its feet, using the very stones of the bridge to aid in my cause. \\n\\nBut should it come to the worst, knowing that my task is not merely to defeat this creature, but to ensure the safety of my companions, I would face it head-on, holding the line for as long as I must, for I am a servant of the Secret Fire, wielder of the Flame of Anor!\\n\\nVictory may come at a cost, but in that moment, it is not only about the battle; it is about the fate of those who follow. As I fall into the abyss, I know my spirit will not be extinguished. For even in death, the fight against darkness continues. \\n\\n**\"You shall not pass!\"** is not just a declaration against one foe, but a testament to the unyielding spirit of light in the face of overwhelming darkness.'}, {'role': 'user', 'content': 'You are revivied as Gandalf the White and must now battle Saouron himself on the battlefield before the dark gate'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(model=gptModel, messages=chatMessages, n=chatCompletionChoices, temperature=samplingTemperature,max_completion_tokens=maxCompletionTokens, top_p=nucleusSampling)"
      ],
      "metadata": {
        "id": "dxvc-yxCl1--"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ThirdAssistantContent = response.choices[0].message.content\n",
        "#Force assitant message to be something: ThirdAssistantContent = \"<something>\""
      ],
      "metadata": {
        "id": "qrluUrmfmC7I"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ThirdAssistantContent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFjLzydvmOmb",
        "outputId": "5a0d65f0-fc9b-47df-a3d3-68d2ce697130"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As Gandalf the White, I rise anew with greater power and purpose, having shed my former self to fulfill the role of the White Wizard, a beacon against the darkness of Sauron. The time has come for a decisive confrontation at the Black Gate of Mordor, where shadows threaten to engulf all of Middle-earth.\n",
            "\n",
            "Upon the desolate battlefield, as Sauron stirs within the depths of his fortress, I would rally the free peoples of Middle-earth—Men, Elves, Dwarves, and even those who have fought in the shadows—for they are united in their defiance against the Dark Lord.\n",
            "\n",
            "In the heart of the gathering storm, I would step forward, the brilliance of my white robes shimmering with the light of hope. With my staff raised high, I would call upon the strength of the land, invoking the very spirit of the earth and the air around me.\n",
            "\n",
            "**\"Sauron! Your tyranny ends here!\"**\n",
            "\n",
            "As he looms above me, a massive and terrible form, I would conjure forth blinding light to pierce the shroud of darkness surrounding him. My voice would resonate with the might of the Valar:\n",
            "\n",
            "**\"You may wield power over shadows, but you shall not snuff out the flame of free will!\"**\n",
            "\n",
            "I would engage Sauron in a battle of will and might, striking with both my staff and the radiant light of my presence, forcing him to confront the light he so despises. In that moment, I would draw upon the unity of our forces—the strength of every ally, every hope, fueling the confrontation.\n",
            "\n",
            "Should the moment come when the Eye of Sauron turns its malevolence towards me, I would stand firm, drawing the courage and resolve of all those who stand against him, channeling their spirit into my actions.\n",
            "\n",
            "With a final cry that reverberates across the plains, I would strike true at the heart of darkness itself, attempting to weaken his grip upon the world:\n",
            "\n",
            "**\"In the name of all that is good, I banish you!\"**\n",
            "\n",
            "Victory may be hard-fought, and it may come at great cost, but as Gandalf the White, I would lead with unyielding resolve. The shadows may retreat today, but the struggle against the Dark Lord shall not end until every heart has the freedom to choose the light over the darkness. Thus, our hope shall endure, and I will not falter in this battle for the future of Middle-earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercises"
      ],
      "metadata": {
        "id": "p1fwf3DB_lOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answering the questions below you may benefit from these references:  \n",
        "\n",
        "\n",
        "1.   Chat completion parameters : https://platform.openai.com/docs/api-reference/chat/create\n",
        "2.   ChatGPT Prompts Library: https://gptbot.io/chatgpt-prompts/\n",
        "3.   Models overview: https://platform.openai.com/docs/models\n",
        "\n"
      ],
      "metadata": {
        "id": "XUSB9DnTBki3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Establish your own chat sequence with max 3. prompts (unless you extend the notebook with additional prompts). You may start with a prompt from the  'ChatGPT Prompts Library' as mentioned above.  \n",
        "Answer:\n",
        "Jeg har indsat mine egne prompts ind i de ovenstående segmenter, jeg har ydermere udvidet antallet af \"Tokens\" altså hvor mange tegn den må svare mig på."
      ],
      "metadata": {
        "id": "bhE77NaXAwzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YlV_25_7KDu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Does it make any difference, if you force assistants 'content' to be somethings else, than that received in the previous reply from ChatGPT. Technically you can do this removing one or more '#Force assitant message to be something:' and specify something else.    \n",
        "Answer:\n",
        "Jeg har forsøgt at gøre dette og det tvinger chat til at svare hvad jeg inputtede i den del. Den printer dermed bare det jeg har skrevet ind. Jeg har efterfølgende slettet denne del, jeg redigerede"
      ],
      "metadata": {
        "id": "mXU-PEtZA0Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain the 'model' parameter specified by the 'gptModel' variable.      \n",
        "Answer:\n",
        "Det er hvilken version af gpt som jeg skal køre på, og dermed hvor \"god\" den er til at udføre opgaverne."
      ],
      "metadata": {
        "id": "m0fNJEjSG5Aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Explain the 'messages' parameter specified by the 'chatMessages'\n",
        "variable.      \n",
        "\n",
        "\n",
        "Answer:\n",
        "Messages er vores interaktion med AI'en, det er her at vores historik og kontekst for det den skal svare findes. Den sammenligner dermed de tidligere svar med det som jeg spørger den om nu.\n",
        "Fra min tekst kan man se hvordan at den bliver ved med at være \"Gandalf\"."
      ],
      "metadata": {
        "id": "MnyEfPT3HkRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain the 'n' parameter specified by the 'chatCompletionChoices' variable.      \n",
        "Answer:\n",
        "Det angiver hvor mange svar som den skal genere til mig"
      ],
      "metadata": {
        "id": "W0ipFRpcH4-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the 'temperature' parameter specified by the 'samplingTemperature' variable.      \n",
        "Answer:\n",
        "Denne paramater angiver hvor \"kreativ\" de svar som jeg får skal være, jeg kan skrue op og ned for kreativiten ved at angive en værdi. Den er sat til \"none\" der bliver til et \"1\" altså et svar med medium kreativitet. Det højeste er 2 og laveste 0."
      ],
      "metadata": {
        "id": "Q2RxcWOzIVM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Explain the 'max_completion_tokens' parameter specified by the 'maxCompletionTokens' variable.      \n",
        "Answer:\n",
        "Dette angiver hvor lange de svar som den giver kan være, jeg har skruet det op til 1000 for at få lange svar."
      ],
      "metadata": {
        "id": "MwNggaKXIrFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Explain the 'top_p' parameter specified by the 'nucleusSampling' variable.      \n",
        "Answer:\n",
        "Dette er med til at bestemme udregning der ligger bag genereringen af de svar som jeg modtager på mine spørgsmål, ligesom temperatur kan man skrue op og ned for dette for at må mere kreative svar.\n",
        "Den beregner ved sandsynlighed det næste ord eller sætning udfra en værdi, når denne værdi er indenfor denne sansynligheds grænse så vælger den det og går videre til næste  "
      ],
      "metadata": {
        "id": "QW7wpSdKI_ed"
      }
    }
  ]
}